{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1170ea43-6d36-4d6e-82c6-d7b94e9cc445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing import Pool\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import lru_cache\n",
    "from PFR_Scraper import DataScraper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68656c57-f5cb-4b02-a72b-ab776031d327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    \n",
    "    _dictionary = {'New York Giants': 'NYG',\n",
    " 'Las Vegas Raiders': 'LVR',\n",
    " 'Los Angeles Chargers': 'LAC',\n",
    " 'Denver Broncos': 'DEN',\n",
    " 'Green Bay Packers': 'GNB',\n",
    " 'Jacksonville Jaguars': 'JAX',\n",
    " 'Washington Redskins': 'WAS',\n",
    " 'Los Angeles Rams': 'LAR',\n",
    " 'Arizona Cardinals': 'ARI',\n",
    " 'Carolina Panthers': 'CAR',\n",
    " 'Baltimore Ravens': 'BAL',\n",
    " 'New York Jets': 'NYJ',\n",
    " 'Miami Dolphins': 'MIA',\n",
    " 'Minnesota Vikings': 'MIN',\n",
    " 'Oakland Raiders': 'OAK',\n",
    " 'Chicago Bears': 'CHI',\n",
    " 'New England Patriots': 'NWE',\n",
    " 'Tennessee Titans': 'TEN',\n",
    " 'New Orleans Saints': 'NOR',\n",
    " 'Cleveland Browns': 'CLE',\n",
    " 'Tampa Bay Buccaneers': 'TAM',\n",
    " 'Buffalo Bills': 'BUF',\n",
    " 'Cincinnati Bengals': 'CIN',\n",
    " 'Houston Texans': 'HOU',\n",
    " 'San Francisco 49ers': 'SFO',\n",
    " 'Atlanta Falcons': 'ATL',\n",
    " 'Washington Football Team': 'WAS',\n",
    " 'Indianapolis Colts': 'IND',\n",
    " 'Seattle Seahawks': 'SEA',\n",
    " 'Pittsburgh Steelers': 'PIT',\n",
    " 'Dallas Cowboys': 'DAL',\n",
    " 'Detroit Lions': 'DET',\n",
    " 'Philadelphia Eagles': 'PHI',\n",
    " 'Kansas City Chiefs': 'KAN'}\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def preprocess_data(self):\n",
    "        #Preprocess the data by calling helper methods in the correct order.\n",
    "        self._convert_columns_to_float()\n",
    "        self._flatten_multiindex_header()\n",
    "        self._handle_missing_values()\n",
    "        self._replace_team_names(self._dictionary)\n",
    "        self._calculate_yards_per_play()\n",
    "        return self.data\n",
    "        \n",
    "    def _convert_columns_to_float(self):\n",
    "        # Convert columns to float if possible\n",
    "        self.data = self.data.applymap(lambda x: pd.to_numeric(x, errors='ignore'))\n",
    "\n",
    "    def _flatten_multiindex_header(self):\n",
    "         # Flatten multi-level column index to single level column index if it exists\n",
    "        if isinstance(self.data.columns, pd.MultiIndex):\n",
    "            self.data.columns = ['_'.join(col).strip('_') if col[1] else col[0] for col in self.data.columns]\n",
    "\n",
    "    def _calculate_yards_per_play(self):\n",
    "        # Calculate yards per play for rushing and receiving\n",
    "        if 'Rushing_Att' in self.data.columns and 'Rushing_Yds' in self.data.columns:\n",
    "            self.data['Y/A'] = self.data.apply(lambda x: 0 if (pd.isna(x['Rushing_Att']) or x['Rushing_Att'] == 0) else x['Rushing_Yds'] / x['Rushing_Att'], axis=1)\n",
    "        if 'Rec' in self.data.columns and 'Receiving_Yds' in self.data.columns:\n",
    "            self.data['Y/R'] = self.data.apply(lambda x: 0 if (pd.isna(x['Rec']) or x['Rec'] == 0) else x['Receiving_Yds'] / x['Rec'], axis=1)\n",
    "            \n",
    "    def _handle_missing_values(self, thresh=0.5):\n",
    "        # Drop rows where most of the columns have string data\n",
    "        str_cols = self.data.select_dtypes(include=['object']).columns\n",
    "        str_counts = self.data[str_cols].apply(lambda x: sum(x.apply(lambda y: isinstance(y, str))), axis=1)\n",
    "        str_prop = str_counts / len(str_cols)\n",
    "        self.data = self.data[str_prop <= thresh]\n",
    "\n",
    "        # Fill applicable missing data\n",
    "        should_fill_mask = (self.data.isnull() | (self.data == 0)).sum() / len(self.data) >= thresh\n",
    "        cols_to_fill = should_fill_mask[should_fill_mask == True].index.tolist()\n",
    "        self.data[cols_to_fill] = self.data[cols_to_fill].fillna(0)\n",
    "        \n",
    "         # Drop columns where most of the rows are null\n",
    "        self.data.dropna(axis=1, thresh=len(self.data) * (1 - thresh), inplace=True)\n",
    "\n",
    "        # Drop rows where most of the columns are null\n",
    "        self.data.dropna(axis=0, thresh=len(self.data.columns) * thresh, inplace=True)\n",
    "\n",
    "        # Drop rows where PPR data is null (if present in dataframe)\n",
    "        if 'PPR' in self.data.columns:\n",
    "            self.data.dropna(subset=['PPR'], inplace=True)\n",
    "\n",
    "        # Drop rows where Rk > 400 if Rk is a column\n",
    "        if 'Rk' in self.data.columns:\n",
    "            self.data = self.data[self.data['Rk'] <= 400]\n",
    "        \n",
    "    def _replace_team_names(self, _dictionary):\n",
    "        if 'Tm' not in self.data.columns:\n",
    "            return self.data\n",
    "\n",
    "        for key, value in _dictionary.items():\n",
    "            mask = self.data['Tm'].str.startswith(key)\n",
    "            if mask.any():\n",
    "                self.data.loc[mask, 'Tm'] = value\n",
    "\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a310f4a-737a-4910-8084-3da4108c43a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MergeAndProcess:\n",
    "    \n",
    "    def __init__(self, player_data, team_data):\n",
    "        self.player_data = player_data\n",
    "        self.team_data = team_data\n",
    "\n",
    "    def merge(self):\n",
    "        # Create a dictionary to map team data to new columns in player data\n",
    "        team_data_map = {\n",
    "            col: col if col in self.player_data.columns else f'Team_{col}' \n",
    "            for col in self.team_data.columns \n",
    "            if col not in ['Year', 'Tm']\n",
    "        }\n",
    "\n",
    "        # Create new columns in player data for team data\n",
    "        self.player_data = self.player_data.assign(**{col: np.nan for col in team_data_map.values()})\n",
    "\n",
    "        # Map team data to new columns in player data based on team and year\n",
    "        self.player_data = self.player_data.set_index(['Year', 'Tm'])\n",
    "        self.team_data = self.team_data.set_index(['Year', 'Tm'])\n",
    "        self.player_data.update(self.team_data.rename(columns=team_data_map))\n",
    "\n",
    "        # Flatten the column index\n",
    "        if isinstance(self.player_data.columns, pd.MultiIndex):\n",
    "            self.player_data.columns = self.player_data.columns.map(lambda x: x[1] if x[0].startswith('Team_') else x[0])\n",
    "\n",
    "        return self.player_data.reset_index()\n",
    "    \n",
    "    def process(self):\n",
    "        # Merge player and team data\n",
    "        merged_data = self.merge()\n",
    "\n",
    "        # Add next year PPR\n",
    "        merged_data['next_year_PPR'] = merged_data.groupby('Player')['PPR'].shift(-1)\n",
    "\n",
    "        # Add PPR per game\n",
    "        merged_data['PPR_per_game'] = merged_data['PPR'] / merged_data['G']\n",
    "        merged_data['PPR_per_game'].fillna(np.nan, inplace=True)\n",
    "\n",
    "        # Convert column types\n",
    "        for col in merged_data.select_dtypes(include=['object']).columns:\n",
    "            try:\n",
    "                merged_data[col] = pd.to_numeric(merged_data[col], errors='raise')\n",
    "            except ValueError:\n",
    "                merged_data[col] = merged_data[col].astype('string')\n",
    "\n",
    "        # Drop missing values\n",
    "        merged_data.loc[merged_data['Year'] != 2022] = merged_data.loc[merged_data['Year'] != 2022].dropna()\n",
    "\n",
    "        # Replace non-alphanumeric characters in player names\n",
    "        merged_data['Player'] = merged_data['Player'].str.replace(r'[^\\w\\s]+', '')\n",
    "\n",
    "        # Reset index\n",
    "        merged_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfad3f74-ee43-4472-8489-5d53e381d911",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "years = list(range(2013, 2023))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5788b32-9290-4750-a8f8-f9d585cda848",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SoupStrainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m scraper \u001b[39m=\u001b[39m DataScraper(years)\n\u001b[0;32m----> 2\u001b[0m player_data \u001b[39m=\u001b[39m scraper\u001b[39m.\u001b[39;49mscrape_player_data()\n\u001b[1;32m      3\u001b[0m team_data \u001b[39m=\u001b[39m scraper\u001b[39m.\u001b[39mscrape_team_data()\n",
      "File \u001b[0;32m~/Coding/GitHub/Practice/PFR_Scraper.py:36\u001b[0m, in \u001b[0;36mDataScraper.scrape_player_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscrape_player_data\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m     35\u001b[0m     \u001b[39mwith\u001b[39;00m ThreadPoolExecutor() \u001b[39mas\u001b[39;00m executor:\n\u001b[0;32m---> 36\u001b[0m         player_data_frames \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(executor\u001b[39m.\u001b[39;49mmap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscrape_data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplayer_urls))\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mconcat([df \u001b[39mfor\u001b[39;00m df \u001b[39min\u001b[39;00m player_data_frames \u001b[39mif\u001b[39;00m df \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39;49mpop())\n\u001b[1;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop(), end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m         \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult(timeout)\n\u001b[1;32m    318\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m         fut\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/Coding/GitHub/Practice/PFR_Scraper.py:23\u001b[0m, in \u001b[0;36mDataScraper.scrape_data\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     20\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mget(url)\n\u001b[1;32m     21\u001b[0m response_text \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mtext\n\u001b[0;32m---> 23\u001b[0m parse_only \u001b[39m=\u001b[39m SoupStrainer(\u001b[39m'\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(response_text, \u001b[39m'\u001b[39m\u001b[39mlxml\u001b[39m\u001b[39m'\u001b[39m, parse_only\u001b[39m=\u001b[39mparse_only)\n\u001b[1;32m     25\u001b[0m tables \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SoupStrainer' is not defined"
     ]
    }
   ],
   "source": [
    "scraper = DataScraper(years)\n",
    "player_data = scraper.scrape_player_data()\n",
    "team_data = scraper.scrape_team_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c37d779",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "player_preprocessor = DataPreprocessor(player_data)\n",
    "player_data = player_preprocessor.preprocess_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3445a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "team_preprocessor = DataPreprocessor(team_data)\n",
    "team_data = team_preprocessor.preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940895fe-aaba-4080-b6fd-cf8393079d83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create instance of MergeAndProcess class\n",
    "merger = MergeAndProcess(player_data, team_data)\n",
    "\n",
    "# call process_data method to merge and process data\n",
    "merged_data = merger.process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1188f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ee228-0aa2-4c93-a638-9e529a18d06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
