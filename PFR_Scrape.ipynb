{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76531f79-3a38-4cc7-8b2b-78de46ac6461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a39918-9d09-4f26-9edb-fc3f479988fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataScraper:\n",
    "    def __init__(self, years):\n",
    "        self.years = years\n",
    "        self.player_urls = [f'https://www.pro-football-reference.com/years/{year}/fantasy.htm' for year in years]\n",
    "        self.team_url = 'https://www.pro-football-reference.com/years/{}/'\n",
    "\n",
    "    def scrape_data(self, urls):\n",
    "        data_frames = []\n",
    "        for url in urls:\n",
    "            year = url.split('/')[-2]  # Extract the year from the URL\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            tables = soup.find_all('table')\n",
    "\n",
    "            df_list = [pd.read_html(str(tables[i]))[0] for i in range(min(len(tables), 2))]\n",
    "            if df_list:\n",
    "                df = pd.concat(df_list)\n",
    "                df['Year'] = float(year)\n",
    "                data_frames.append(df)\n",
    "\n",
    "        return pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    def scrape_player_data(self):\n",
    "        return self.scrape_data(self.player_urls)\n",
    "\n",
    "    def scrape_team_data(self):\n",
    "        team_urls = [self.team_url.format(year) for year in self.years]\n",
    "        team_data = self.scrape_data(team_urls)\n",
    "        return team_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0551911f-a955-48d5-abb8-bbd607af9ff6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    \n",
    "    dictionary = {'New York Giants': 'NYG',\n",
    " 'Las Vegas Raiders': 'LVR',\n",
    " 'Los Angeles Chargers': 'LAC',\n",
    " 'Denver Broncos': 'DEN',\n",
    " 'Green Bay Packers': 'GNB',\n",
    " 'Jacksonville Jaguars': 'JAX',\n",
    " 'Washington Redskins': 'WAS',\n",
    " 'Los Angeles Rams': 'LAR',\n",
    " 'Arizona Cardinals': 'ARI',\n",
    " 'Carolina Panthers': 'CAR',\n",
    " 'Baltimore Ravens': 'BAL',\n",
    " 'New York Jets': 'NYJ',\n",
    " 'Miami Dolphins': 'MIA',\n",
    " 'Minnesota Vikings': 'MIN',\n",
    " 'Oakland Raiders': 'OAK',\n",
    " 'Chicago Bears': 'CHI',\n",
    " 'New England Patriots': 'NWE',\n",
    " 'Tennessee Titans': 'TEN',\n",
    " 'New Orleans Saints': 'NOR',\n",
    " 'Cleveland Browns': 'CLE',\n",
    " 'Tampa Bay Buccaneers': 'TAM',\n",
    " 'Buffalo Bills': 'BUF',\n",
    " 'Cincinnati Bengals': 'CIN',\n",
    " 'Houston Texans': 'HOU',\n",
    " 'San Francisco 49ers': 'SFO',\n",
    " 'Atlanta Falcons': 'ATL',\n",
    " 'Washington Football Team': 'WAS',\n",
    " 'Indianapolis Colts': 'IND',\n",
    " 'Seattle Seahawks': 'SEA',\n",
    " 'Pittsburgh Steelers': 'PIT',\n",
    " 'Dallas Cowboys': 'DAL',\n",
    " 'Detroit Lions': 'DET',\n",
    " 'Philadelphia Eagles': 'PHI',\n",
    " 'Kansas City Chiefs': 'KAN'}\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def try_convert_to_float(self, x):\n",
    "        try:\n",
    "            return float(x)\n",
    "        except:\n",
    "            if x == '' or pd.isna(x):\n",
    "                return np.nan\n",
    "            else:\n",
    "                return x\n",
    "\n",
    "    def convert_columns_to_float(self):\n",
    "        # Convert all columns to float if possible\n",
    "        self.data = self.data.applymap(self.try_convert_to_float)\n",
    "        self.data = self.data.astype(float, errors='ignore')\n",
    "\n",
    "    def flatten_multiindex_header(self):\n",
    "        # Flatten multi-level column index to single level column index if it exists\n",
    "        if isinstance(self.data.columns, pd.MultiIndex):\n",
    "            level1 = self.data.columns.get_level_values(0)\n",
    "            level2 = self.data.columns.get_level_values(1)\n",
    "\n",
    "            # Count duplicates in level2\n",
    "            duplicates = level2.value_counts() > 1\n",
    "\n",
    "            # Create new column names\n",
    "            new_columns = []\n",
    "            for col_level1, col_level2 in zip(level1, level2):\n",
    "                if duplicates[col_level2]:\n",
    "                    new_columns.append(f'{col_level1}_{col_level2}')\n",
    "                elif col_level2 == '':\n",
    "                    new_columns.append(col_level1)\n",
    "                else:\n",
    "                    new_columns.append(col_level2)\n",
    "\n",
    "            # Replace the MultiIndex header with the new flattened header\n",
    "            self.data.columns = new_columns\n",
    "        return self.data\n",
    " \n",
    "    def calculate_yards_per_attempt(self):\n",
    "    # Calculate yards per rushing attempt\n",
    "        if 'Rushing_Att' in self.data.columns and 'Rushing_Yds' in self.data.columns:\n",
    "            self.data['Y/A'] = self.data.apply(lambda x: 0 if (pd.isna(x['Rushing_Att']) or x['Rushing_Att'] == 0) else x['Rushing_Yds'] / x['Rushing_Att'], axis=1)\n",
    "\n",
    "    def calculate_yards_per_reception(self):\n",
    "    # Calculate yards per reception\n",
    "        if 'Rec' in self.data.columns and 'Receiving_Yds' in self.data.columns:\n",
    "            self.data['Y/R'] = self.data.apply(lambda x: 0 if (pd.isna(x['Rec']) or x['Rec'] == 0) else x['Receiving_Yds'] / x['Rec'], axis=1)\n",
    "            \n",
    "    def handle_missing_values(self, thresh=0.5):\n",
    "    \n",
    "        # Drop rows where most of the columns have string data\n",
    "        self.data = self.data[~(np.sum(np.vectorize(isinstance)(self.data.values, str), axis=1) > thresh * len(self.data.columns))]\n",
    "\n",
    "        def should_fill(col):\n",
    "            na_and_zero_count = (col.apply(lambda x: pd.isna(x) or x == 0)).sum()\n",
    "            return na_and_zero_count / len(col) >= 0.7\n",
    "\n",
    "        should_fill_mask = self.data.apply(should_fill)\n",
    "        fill_mask = self.data.apply(lambda col: col.isna() & should_fill_mask[col.name])\n",
    "        self.data = self.data.mask(fill_mask, 0.0)\n",
    "\n",
    "        # Drop columns where most of the rows are null\n",
    "        self.data = self.data.drop(columns=self.data.columns[self.data.isnull().mean() > thresh], errors='ignore')\n",
    "\n",
    "        # Drop rows where most of the columns are null\n",
    "        self.data = self.data.dropna(thresh=thresh * len(self.data.columns))\n",
    "\n",
    "        # Drop rows where PPR data is null (if present in dataframe)\n",
    "        if 'PPR' in self.data.columns:\n",
    "            self.data = self.data.dropna(subset=['PPR'])\n",
    "\n",
    "\n",
    "    def replace_team_names(self, dictionary):\n",
    "        for key, value in dictionary.items():\n",
    "            mask = self.data['Tm'].str.startswith(key)\n",
    "            if mask.any():\n",
    "                self.data.loc[mask, 'Tm'] = value\n",
    "        return self.data\n",
    "        \n",
    "    def feature_engineering(self):\n",
    "        # Create new features or modify existing ones based on domain knowledge\n",
    "        pass\n",
    "\n",
    "    def feature_scaling(self):\n",
    "        # Scale numerical features to a standard range, e.g., using Min-Max scaling or StandardScaler from sklearn\n",
    "        pass\n",
    "\n",
    "    def normalize_data(self):\n",
    "        # Normalize data to reduce the impact of outliers or skewed distributions, e.g., using log transformation or Box-Cox transformation\n",
    "        pass\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        self.convert_columns_to_float()\n",
    "        self.flatten_multiindex_header()\n",
    "        self.handle_missing_values()\n",
    "        self.replace_team_names(dictionary=self.dictionary)  # pass dictionary argument\n",
    "        self.calculate_yards_per_attempt()\n",
    "        self.calculate_yards_per_reception()\n",
    "        # Call other preprocessing methods in the correct order\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d80ff8c-54cd-40e7-a6c1-4da66f8a26d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MergeAndProcess:\n",
    "    def __init__(self, player_data, team_data):\n",
    "        self.player_data = player_data\n",
    "        self.team_data = team_data\n",
    "\n",
    "    def merge(self):\n",
    "        # Create a dictionary to map team data to new columns in player data\n",
    "        team_data_map = {}\n",
    "        for col in self.team_data.columns:\n",
    "            if col not in ['Year', 'Tm']:\n",
    "                if col in self.player_data.columns:\n",
    "                    team_data_map[col] = col\n",
    "                else:\n",
    "                    team_data_map[col] = f'Team_{col}'\n",
    "\n",
    "        # Create new columns in player data for team data\n",
    "        for col in team_data_map.values():\n",
    "            self.player_data[col] = np.nan\n",
    "\n",
    "        # Map team data to new columns in player data based on team and year\n",
    "        self.player_data.set_index(['Year', 'Tm'], inplace=True)\n",
    "        self.team_data.set_index(['Year', 'Tm'], inplace=True)\n",
    "        self.player_data.update(self.team_data.rename(columns=team_data_map))\n",
    "\n",
    "        # Flatten the column index\n",
    "        if isinstance(self.player_data.columns, pd.MultiIndex):\n",
    "            level1 = self.player_data.columns.get_level_values(0)\n",
    "            level2 = self.player_data.columns.get_level_values(1)\n",
    "            new_columns = []\n",
    "            for col_level1, col_level2 in zip(level1, level2):\n",
    "                if col_level1.startswith('Team_'):\n",
    "                    new_columns.append(col_level2)\n",
    "                else:\n",
    "                    new_columns.append(col_level1)\n",
    "            self.player_data.columns = new_columns\n",
    "\n",
    "        return self.player_data.reset_index()\n",
    "\n",
    "    def process(self):\n",
    "        \n",
    "        # Merge player and team data\n",
    "        merged_data = self.merge()\n",
    "        \n",
    "        # Add next year PPR\n",
    "        merged_data['next_year_PPR'] = merged_data.groupby('Player')['PPR'].shift(-1)\n",
    "\n",
    "        # Add PPR per game\n",
    "        merged_data['PPR_per_game'] = np.nan\n",
    "        try:\n",
    "            merged_data['PPR_per_game'] = merged_data['PPR'] / merged_data['G']\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Convert column types\n",
    "        for col in merged_data.columns:\n",
    "            if merged_data[col].dtype == 'object':\n",
    "                try:\n",
    "                    merged_data[col] = pd.to_numeric(merged_data[col], errors='raise').astype('float')\n",
    "                except ValueError:\n",
    "                    merged_data[col] = merged_data[col].astype('string')\n",
    "            else:\n",
    "                dtype = merged_data[col].dtype\n",
    "                merged_data[col] = merged_data[col].astype(dtype)\n",
    "\n",
    "        # Drop missing values\n",
    "        merged_data = merged_data.dropna()\n",
    "        \n",
    "        # Reset index\n",
    "        merged_data = merged_data.reset_index(drop=True)\n",
    "        \n",
    "        # Replace non-alphanumeric characters in player names\n",
    "        merged_data['Player'] = merged_data['Player'].str.replace(r'[^\\w\\s]+', '')\n",
    "        \n",
    "        return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77815273-1c01-40d0-804a-6515cf0825fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "years = list(range(2013, 2022))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6f45c-4d9c-4d37-a74c-cad5733bc734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scraper = DataScraper(years)\n",
    "player_data = scraper.scrape_player_data()\n",
    "team_data = scraper.scrape_team_data()\n",
    "\n",
    "player_preprocessor = DataPreprocessor(player_data)\n",
    "player_data = player_preprocessor.preprocess_data()\n",
    "\n",
    "team_preprocessor = DataPreprocessor(team_data)\n",
    "team_data = team_preprocessor.preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc2f767-1094-477c-9268-662d8f97d85e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create instance of MergeAndProcess class\n",
    "merger = MergeAndProcess(player_data, team_data)\n",
    "\n",
    "# call process_data method to merge and process data\n",
    "merged_data = merger.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c40e998-d6ba-4f89-97dc-b7615d6edd73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4469baf-6612-499d-bea5-49d68381397b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the merged_data DataFrame into training/validation (2015-2020) and testing (2021)\n",
    "train_val_data = merged_data[merged_data['Year'] < 2021]\n",
    "test_data = merged_data[merged_data['Year'] == 2021]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec00d54f-5ada-4527-831d-f879b4fc2e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate dataframes by position\n",
    "positions = merged_data['FantPos'].unique()\n",
    "position_dfs = {position: train_val_data[train_val_data['FantPos'] == position] for position in positions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a19ab23-6569-4bce-a256-dd519dcd893d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set a lookback period (e.g., 3 years)\n",
    "lookback = 2\n",
    "\n",
    "# Convert data into sequences\n",
    "sequences = {}\n",
    "for position, df in position_dfs.items():\n",
    "    player_group = df.groupby('Player')\n",
    "    position_sequences = []\n",
    "    for _, group in player_group:\n",
    "        group = group.sort_values('Year')\n",
    "        for i in range(len(group) - lookback):\n",
    "            sequence = group.iloc[i:i+lookback+1]\n",
    "            position_sequences.append(sequence)\n",
    "    sequences[position] = pd.concat(position_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967dbfa-4f3c-4493-955b-70bb1a8523f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93655e7a-9b96-4cee-ac27-2e3e778b9678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85540cea-423e-4ff0-a523-9edec8ec6ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate over the data frames\n",
    "for position, df in sequences.items():\n",
    "    # Filter out non-numeric columns and the predicted variable\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if 'next_year_PPR' in numeric_cols:\n",
    "        numeric_cols.remove('next_year_PPR')\n",
    "\n",
    "       # Prepare input and output data\n",
    "    X = np.array([df[numeric_cols].iloc[i:i+lookback].values for i in range(len(df) - lookback)]).astype(np.float32)\n",
    "    y = df['next_year_PPR'].values[lookback:].astype(np.float32)\n",
    "\n",
    "\n",
    "    # Create and train the LSTM model\n",
    "    model = create_lstm_model((lookback, len(numeric_cols)))\n",
    "    model.fit(X, y, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    # Store the trained model\n",
    "    models[position] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9bfd29-8fbb-41a9-b92e-fc3de3ae8764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_next_year_ppr(test_data, models, lookback):\n",
    "    test_sequences = {}\n",
    "\n",
    "    # Iterate over test_data to create position-specific sequences\n",
    "    for position, df in test_data.groupby('FantPos'):\n",
    "        player_group = df.groupby('Player')\n",
    "        position_sequences = []\n",
    "        for _, group in player_group:\n",
    "            group = group.sort_values('Year')\n",
    "            if len(group) >= lookback + 1:\n",
    "                sequence = group.iloc[-(lookback + 1):]\n",
    "                position_sequences.append(sequence)\n",
    "        test_sequences[position] = pd.concat(position_sequences)\n",
    "\n",
    "    # Prepare input data for the models and make predictions\n",
    "    predicted_ppr = []\n",
    "    for position, df in test_sequences.items():\n",
    "        if position in models:\n",
    "            model = models[position]\n",
    "            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "            if 'next_year_PPR' in numeric_cols:\n",
    "                numeric_cols.remove('next_year_PPR')\n",
    "            X = np.array([df[numeric_cols].iloc[i:i+lookback].values for i in range(len(df) - lookback)]).astype(np.float32)\n",
    "            y_pred = model.predict(X).flatten()\n",
    "\n",
    "            # Create a DataFrame of predicted PPR values for each player\n",
    "            players = df['Player'].iloc[lookback:].values\n",
    "            years = df['Year'].iloc[lookback:].values\n",
    "            predicted_ppr.extend(list(zip(players, years, y_pred)))\n",
    "\n",
    "    # Convert the list of tuples to a DataFrame\n",
    "    predicted_ppr_df = pd.DataFrame(predicted_ppr, columns=['Player', 'Year', 'Predicted_PPR'])\n",
    "\n",
    "    return predicted_ppr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "11d8ae2a-0560-46cc-8d8e-c192193bd812",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Year</th>\n",
       "      <th>Predicted_PPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Player, Year, Predicted_PPR]\n",
       "Index: []"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ppr_df = predict_next_year_ppr(test_data, models, lookback)\n",
    "predicted_ppr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377e84f-14ed-4756-b99c-52d2651761fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3175c2-7968-409e-8f60-4958cf1877db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
